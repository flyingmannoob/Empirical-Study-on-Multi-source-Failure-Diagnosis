{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "import time\n",
    "\n",
    "tz = pytz.timezone('Asia/Shanghai')\n",
    "def ts_to_date(timestamp):\n",
    "    return datetime.fromtimestamp(timestamp//1000, tz).strftime('%Y-%m-%d')\n",
    "#     return datetime.fromtimestamp(timestamp//1000, tz).strftime('%m%d')\n",
    "\n",
    "def time_to_ts(ctime):\n",
    "    try:\n",
    "        timeArray = time.strptime(ctime, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    except:\n",
    "        timeArray = time.strptime(ctime, '%Y-%m-%d %H:%M:%S')\n",
    "    return int(time.mktime(timeArray))*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "import json\n",
    "\n",
    "class TraceUtils:\n",
    "    def __init__(self, data_dir, dataset='gaia'):\n",
    "        self.data_dir = data_dir\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def get_trace_by_day(self, day: int):\n",
    "        day = f'0{day}' if day < 10 else str(day)\n",
    "        temp = []\n",
    "        for service in os.listdir(self.data_dir):\n",
    "            filepath = os.path.join(self.data_dir, \n",
    "                                                 f'{service}/trace_{service}_2021-07-{day}.csv')\n",
    "            if not os.path.exists(filepath):\n",
    "                continue\n",
    "            temp.append(pd.read_csv(filepath, index_col=0))\n",
    "        data = pd.concat(temp, ignore_index=True)\n",
    "        data['timestamp'] = data['timestamp'].apply(time_to_ts)\n",
    "        return data\n",
    "\n",
    "    def get_trace_by_ts(self, ts):\n",
    "        date = ''.join(ts_to_date(ts).split('-')[1: ])\n",
    "#         data = pd.read_csv(os.path.join(self.data_dir, f'{date}.csv')) # gaia\n",
    "        data = pd.read_csv(os.path.join(self.data_dir, f'trace_{date}.csv')) # 21aiops\n",
    "        return data\n",
    "    \n",
    "    # lagency/duration需要减去子调用的最大值\n",
    "    def data_process(self, start_ts, end_ts):\n",
    "        day = int(ts_to_date(start_ts).split('-')[-1])\n",
    "        node = 'service_name' if self.dataset == 'gaia' else 'cmdb_id'\n",
    "        if self.dataset == 'gaia':\n",
    "            node = 'service_name'\n",
    "            column = 'lagency'\n",
    "            df = self.get_trace_by_day(day)\n",
    "            if (start_ts is not None) and (end_ts is not None):\n",
    "                sub_df = df[(df['timestamp']>=start_ts)&(df['timestamp']<end_ts)]\n",
    "            else:\n",
    "                sub_df = df\n",
    "            csub_df = sub_df.groupby(['trace_id', 'parent_id'], as_index=False).max()\n",
    "            csub_df = csub_df[[\n",
    "                    'parent_id', node, column\n",
    "                ]].rename(columns={'parent_id': 'span_id', node: f'c{node}', column: f'c{column}'})\n",
    "            data = pd.merge(sub_df, csub_df, on='span_id', how='left').fillna(0)\n",
    "            data['real_duration'] = data[column] - data[f'c{column}']\n",
    "        elif self.dataset == '21aiops':\n",
    "#             node = 'cmdb_id'\n",
    "#             column = 'duration'\n",
    "            df = self.get_trace_by_ts(start_ts)\n",
    "            df['timestamp'] = df['timestamp'] if df['timestamp'].values[0] >= 1e12 else df['timestamp']*1000\n",
    "            data = df[(df['timestamp']>=start_ts)&(df['timestamp']<end_ts)]\n",
    "        else:\n",
    "            raise Exception('Unknow dataset!')\n",
    "        return data\n",
    "    \n",
    "class TraceAnalysis(Process):\n",
    "    def __init__(self, cases, data_dir, pid, load, dataset='gaia', config=None):\n",
    "        super().__init__()\n",
    "        self.id = pid\n",
    "        self.cases = cases.iloc[pid*load: (pid+1)*load]\n",
    "        self.tu = TraceUtils(data_dir, dataset)\n",
    "        self.config = config\n",
    "        self.dataset = dataset\n",
    "        if config is None:\n",
    "            self.config = {}\n",
    "            self.config['threshold'] = 50 # 认为异常的duration阈值\n",
    "            self.config['minute'] = 60000\n",
    "        self.res = dict(zip(list(self.cases.index), [set() for _ in range(len(self.cases))])) # 报告可疑微服务\n",
    "        self.time_used = None\n",
    "    \n",
    "    def analysis(self):\n",
    "        start_time = time.time()\n",
    "        if self.dataset == 'gaia':\n",
    "            node = 'service_name'\n",
    "        elif self.dataset == '21aiops':\n",
    "            node = 'cmdb_id'\n",
    "        else:\n",
    "            raise Exception('Unknow dataset!')\n",
    "        for case_id, case in self.cases.iterrows():\n",
    "            start_ts = time_to_ts(case['st_time'])\n",
    "            end_ts = time_to_ts(case['ed_time'])\n",
    "            df = self.tu.data_process(start_ts, end_ts) \n",
    "            chosen_df = df[df['real_duration']>self.config['threshold']]\n",
    "            self.res[case_id].update(list(chosen_df[node].unique()))\n",
    "            self.res[case_id].update(list(chosen_df[f'c{node}'].unique()))\n",
    "            if 0 in self.res[case_id]:\n",
    "                self.res[case_id].remove(0)\n",
    "            if np.nan in self.res[case_id]:\n",
    "                self.res[case_id].remove(np.nan)\n",
    "        end_time = time.time()\n",
    "        self.time_used = end_time - start_time\n",
    "    \n",
    "    def save_res(self, savepath):\n",
    "        for key in self.res:\n",
    "            self.res[key] = list(self.res[key])\n",
    "        with open(savepath, 'w') as f:\n",
    "            json.dump(self.res, f)\n",
    "        print(f'{self.id} Time used: ', self.time_used)\n",
    "        print('Save successfully!')\n",
    "    \n",
    "    def run(self):\n",
    "        self.analysis()\n",
    "        self.save_res(f'{self.dataset}/trace/{self.dataset}_trace_{self.id}.json')\n",
    "        with open(f'{self.dataset}/trace/time_used_{self.id}', 'w') as f:\n",
    "            f.write(f'{self.time_used}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置\n",
    "trace_path = '/home/u2120210568/jupyterfiles/jinwa/unirca/new_trace/'\n",
    "label_path = '/home/u2120210568/multi_rca/case/gaia_resplit.csv' # 故障case的路径\n",
    "demo_labels = pd.read_csv(label_path, index_col=0)\n",
    "demo_labels = demo_labels[demo_labels['data_type']=='test']\n",
    "processes = []\n",
    "for pid in range(20):\n",
    "    processes.append(TraceAnalysis(demo_labels, trace_path, pid, 47))\n",
    "    processes[-1].start()\n",
    "    print(f'process {pid} starts...')\n",
    "for pid in range(20):\n",
    "    processes[pid].join()\n",
    "    print(f'process {pid} ends.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21挑战赛 配置\n",
    "trace_path = '/home/u2120210568/jupyterfiles/linzihan/multi_rca/new/2021aiops/process_row_trace'\n",
    "label_path = '/home/u2120210568/multi_rca/case/21aiops_resplit.csv'\n",
    "demo_labels = pd.read_csv(label_path, index_col=0)\n",
    "processes = []\n",
    "for pid in range(10):\n",
    "    processes.append(TraceAnalysis(demo_labels[demo_labels['data_type']=='test'], \n",
    "                                   trace_path, pid, 8, '21aiops'))\n",
    "    processes[-1].start()\n",
    "    print(f'process {pid} starts...')\n",
    "for pid in range(10):\n",
    "    processes[pid].join()\n",
    "    print(f'process {pid} ends.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tz = pytz.timezone('Asia/Shanghai')\n",
    "def ts_to_date(timestamp):\n",
    "    return datetime.fromtimestamp(timestamp//1000, tz).strftime('%Y-%m-%d')\n",
    "\n",
    "def time_to_ts(ctime):\n",
    "    try:\n",
    "        # 先尝试解析包含小时和分钟的格式\n",
    "        timeArray = time.strptime(ctime, '%Y/%m/%d %H:%M')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # 如果失败，尝试只有日期的格式\n",
    "            timeArray = time.strptime(ctime, '%Y/%m/%d')\n",
    "        except ValueError:\n",
    "            # 如果仍然失败，记录错误或返回一个默认值\n",
    "            print(f\"Failed to parse date: {ctime}\")\n",
    "            return None\n",
    "    return int(time.mktime(timeArray))*1000\n",
    "\n",
    "class TraceUtils:\n",
    "    def __init__(self, data_dir, dataset='gaia'):\n",
    "        self.data_dir = data_dir\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def get_trace_by_day(self, day: int):\n",
    "        day = f'0{day}' if day < 10 else str(day)\n",
    "        temp = []\n",
    "        for service in os.listdir(self.data_dir):\n",
    "            filepath = os.path.join(self.data_dir, \n",
    "                                                 f'{service}/trace_{service}_2021-07-{day}.csv')\n",
    "            if not os.path.exists(filepath):\n",
    "                continue\n",
    "            temp.append(pd.read_csv(filepath, index_col=0))\n",
    "        data = pd.concat(temp, ignore_index=True)\n",
    "        data['timestamp'] = data['timestamp'].apply(time_to_ts)\n",
    "        return data\n",
    "\n",
    "    def get_trace_by_ts(self, ts):\n",
    "        date = ''.join(ts_to_date(ts).split('-')[1: ])\n",
    "        data = pd.read_csv(os.path.join(self.data_dir, f'trace_{date}.csv')) # 21aiops\n",
    "        return data\n",
    "    \n",
    "    # lagency/duration需要减去子调用的最大值\n",
    "    def data_process(self, start_ts, end_ts):\n",
    "        day = int(ts_to_date(start_ts).split('-')[-1])\n",
    "        node = 'service_name' if self.dataset == 'gaia' else 'cmdb_id'\n",
    "        if self.dataset == 'gaia':\n",
    "            node = 'service_name'\n",
    "            column = 'lagency'\n",
    "            df = self.get_trace_by_day(day)\n",
    "            if (start_ts is not None) and (end_ts is not None):\n",
    "                sub_df = df[(df['timestamp']>=start_ts)&(df['timestamp']<end_ts)]\n",
    "            else:\n",
    "                sub_df = df\n",
    "            csub_df = sub_df.groupby(['trace_id', 'parent_id'], as_index=False).max()\n",
    "            csub_df = csub_df[[\n",
    "                    'parent_id', node, column\n",
    "                ]].rename(columns={'parent_id': 'span_id', node: f'c{node}', column: f'c{column}'})\n",
    "            data = pd.merge(sub_df, csub_df, on='span_id', how='left').fillna(0)\n",
    "            data['real_duration'] = data[column] - data[f'c{column}']\n",
    "        elif self.dataset == '21aiops':\n",
    "            df = self.get_trace_by_ts(start_ts)\n",
    "            df['timestamp'] = df['timestamp'] if df['timestamp'].values[0] >= 1e12 else df['timestamp']*1000\n",
    "            data = df[(df['timestamp']>=start_ts)&(df['timestamp']<end_ts)]\n",
    "        elif self.dataset == '22aiops':\n",
    "            node = 'cmdb_id'\n",
    "            column = 'duration'\n",
    "            df = pd.read_csv('/Users/fengxiaoyu/Desktop/PDiagnose/初赛评分数据/trace.csv')\n",
    "            if (start_ts is not None) and (end_ts is not None):\n",
    "                sub_df = df[(df['timestamp']>=start_ts)&(df['timestamp']<end_ts)]\n",
    "            else:\n",
    "                sub_df = df\n",
    "            csub_df = sub_df.groupby(['span_id', 'parent_span'], as_index=False).max()\n",
    "            csub_df = csub_df[[\n",
    "                    'parent_span', node, column\n",
    "                ]].rename(columns={'parent_span': 'span_id', node: f'c{node}', column: f'c{column}'})\n",
    "            data = pd.merge(sub_df, csub_df, on='span_id', how='left').fillna(0)\n",
    "            data['real_duration'] = data[column] - data[f'c{column}']\n",
    "        else:\n",
    "            raise Exception('Unknow dataset!')\n",
    "        return data\n",
    "    \n",
    "class TraceAnalysis():\n",
    "    def __init__(self, cases, data_dir, pid, load, dataset='gaia', config=None):\n",
    "        super().__init__()\n",
    "        self.id = pid\n",
    "        self.cases = cases.iloc[pid*load: (pid+1)*load]\n",
    "        self.tu = TraceUtils(data_dir, dataset)\n",
    "        self.config = config\n",
    "        self.dataset = dataset\n",
    "        if config is None:\n",
    "            self.config = {}\n",
    "            self.config['threshold'] = 50 # 认为异常的duration阈值\n",
    "            self.config['minute'] = 60000\n",
    "        self.res = dict(zip(list(self.cases.index), [set() for _ in range(len(self.cases))])) # 报告可疑微服务\n",
    "        self.time_used = None\n",
    "    \n",
    "    def analysis(self):\n",
    "        start_time = time.time()\n",
    "        if self.dataset == 'gaia':\n",
    "            node = 'service_name'\n",
    "        elif self.dataset == '21aiops':\n",
    "            node = 'cmdb_id'\n",
    "        elif self.dataset == '22aiops':\n",
    "            node = 'cmdb_id'\n",
    "        else:\n",
    "            raise Exception('Unknow dataset!')\n",
    "        for case_id, case in self.cases.iterrows():\n",
    "            start_ts = time_to_ts(case['start'])\n",
    "            end_ts = time_to_ts(case['end'])\n",
    "            df = self.tu.data_process(start_ts, end_ts) \n",
    "            chosen_df = df[df['real_duration']>self.config['threshold']]\n",
    "            self.res[case_id].update(list(chosen_df[node].unique()))\n",
    "            self.res[case_id].update(list(chosen_df[f'c{node}'].unique()))\n",
    "            if 0 in self.res[case_id]:\n",
    "                self.res[case_id].remove(0)\n",
    "            if np.nan in self.res[case_id]:\n",
    "                self.res[case_id].remove(np.nan)\n",
    "        end_time = time.time()\n",
    "        self.time_used = end_time - start_time\n",
    "    \n",
    "    def save_res(self, savepath):\n",
    "        for key in self.res:\n",
    "            self.res[key] = list(self.res[key])\n",
    "        with open(savepath, 'w') as f:\n",
    "            json.dump(self.res, f)\n",
    "        print(f'{self.id} Time used: ', self.time_used)\n",
    "        print('Save successfully!')\n",
    "    \n",
    "    def run(self):\n",
    "        self.analysis()\n",
    "        self.save_res(f'{self.dataset}/trace/{self.dataset}_trace_{self.id}.json')\n",
    "        with open(f'{self.dataset}/trace/time_used_{self.id}', 'w') as f:\n",
    "            f.write(f'{self.time_used}')\n",
    "\n",
    "# 22挑战赛 配置\n",
    "trace_path = '/Users/fengxiaoyu/Desktop/PDiagnose/初赛评分数据/trace.csv'\n",
    "label_path = '/Users/fengxiaoyu/Desktop/PDiagnose/22AIOps_run_table.csv'\n",
    "demo_labels = pd.read_csv(label_path, index_col=0)\n",
    "processes = []\n",
    "# 只创建一个实例\n",
    "pid = 0\n",
    "load = len(demo_labels)\n",
    "analyzer = TraceAnalysis(demo_labels[(demo_labels['type'] == 'test') & (demo_labels['level'] == 'pod')], trace_path, pid, load, '22aiops')\n",
    "analyzer.analysis()\n",
    "analyzer.save_res(f'{analyzer.dataset}/trace/{analyzer.dataset}_trace_{analyzer.id}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1711079840000000\n",
      "(39179309, 11)\n",
      "1711079920000000\n",
      "(39179309, 11)\n",
      "1711081240000000\n",
      "(39179309, 11)\n",
      "1711097700000000\n",
      "(39179309, 11)\n",
      "1711099140000000\n",
      "(39179309, 11)\n",
      "1711109040000000\n",
      "(39179309, 11)\n",
      "1711110330000000\n",
      "(39179309, 11)\n",
      "1711115030000000\n",
      "(39179309, 11)\n",
      "1711116250000000\n",
      "(39179309, 11)\n",
      "1711119050000000\n",
      "(39179309, 11)\n",
      "1711120370000000\n",
      "(39179309, 11)\n",
      "1711126070000000\n",
      "(39179309, 11)\n",
      "1711129070000000\n",
      "(39179309, 11)\n",
      "1711132860000000\n",
      "(39179309, 11)\n",
      "1711134100000000\n",
      "(39179309, 11)\n",
      "1711137100000000\n",
      "(39179309, 11)\n",
      "1711138420000000\n",
      "(39179309, 11)\n",
      "1711141220000000\n",
      "(39179309, 11)\n",
      "1711142360000000\n",
      "(39179309, 11)\n",
      "1711143350000000\n",
      "(39179309, 11)\n",
      "1711144690000000\n",
      "(39179309, 11)\n",
      "1711150490000000\n",
      "(39179309, 11)\n",
      "1711156490000000\n",
      "(39179309, 11)\n",
      "1711160530000000\n",
      "(39179309, 11)\n",
      "1711161620000000\n",
      "(39179309, 11)\n",
      "1711167220000000\n",
      "(39179309, 11)\n",
      "1711168710000000\n",
      "(39179309, 11)\n",
      "1711171710000000\n",
      "(39179309, 11)\n",
      "1711174510000000\n",
      "(39179309, 11)\n",
      "1711177310000000\n",
      "(39179309, 11)\n",
      "1711180310000000\n",
      "(39179309, 11)\n",
      "1711183110000000\n",
      "(39179309, 11)\n",
      "1711186110000000\n",
      "(39179309, 11)\n",
      "1711189110000000\n",
      "(39179309, 11)\n",
      "1711190130000000\n",
      "(39179309, 11)\n",
      "1711193130000000\n",
      "(39179309, 11)\n",
      "1711194470000000\n",
      "(39179309, 11)\n",
      "1711197270000000\n",
      "(39179309, 11)\n",
      "1711200270000000\n",
      "(39179309, 11)\n",
      "1711201670000000\n",
      "(39179309, 11)\n",
      "1711203160000000\n",
      "(39179309, 11)\n",
      "1711206160000000\n",
      "(39179309, 11)\n",
      "1711207680000000\n",
      "(39179309, 11)\n",
      "1711210680000000\n",
      "(39179309, 11)\n",
      "1711213680000000\n",
      "(39179309, 11)\n",
      "1711216680000000\n",
      "(39179309, 11)\n",
      "1711219680000000\n",
      "(39179309, 11)\n",
      "1711220800000000\n",
      "(39179309, 11)\n",
      "1711223600000000\n",
      "(39179309, 11)\n",
      "1711226600000000\n",
      "(39179309, 11)\n",
      "1711229600000000\n",
      "(39179309, 11)\n",
      "1711232600000000\n",
      "(39179309, 11)\n",
      "1711234100000000\n",
      "(39179309, 11)\n",
      "1711235120000000\n",
      "(39179309, 11)\n",
      "1711237920000000\n",
      "(39179309, 11)\n",
      "1711240920000000\n",
      "(39179309, 11)\n",
      "1711243720000000\n",
      "(39179309, 11)\n",
      "1711246720000000\n",
      "(39179309, 11)\n",
      "1711249720000000\n",
      "(39179309, 11)\n",
      "1711252720000000\n",
      "(39179309, 11)\n",
      "1711253840000000\n",
      "(39179309, 11)\n",
      "1711256640000000\n",
      "(39179309, 11)\n",
      "1711257840000000\n",
      "(39179309, 11)\n",
      "1711259130000000\n",
      "(39179309, 11)\n",
      "1711262130000000\n",
      "(39179309, 11)\n",
      "1711265130000000\n",
      "(39179309, 11)\n",
      "1711266630000000\n",
      "(39179309, 11)\n",
      "1711268070000000\n",
      "(39179309, 11)\n",
      "1711269270000000\n",
      "(39179309, 11)\n",
      "1711270610000000\n",
      "(39179309, 11)\n",
      "1711273410000000\n",
      "(39179309, 11)\n",
      "1711274710000000\n",
      "(39179309, 11)\n",
      "1711276410000000\n",
      "(39179309, 11)\n",
      "1711279410000000\n",
      "(39179309, 11)\n",
      "1711282410000000\n",
      "(39179309, 11)\n",
      "1711285410000000\n",
      "(39179309, 11)\n",
      "1711288410000000\n",
      "(39179309, 11)\n",
      "1711291410000000\n",
      "(39179309, 11)\n",
      "1711294410000000\n",
      "(39179309, 11)\n",
      "0 Time used:  4691.080677986145\n",
      "Save successfully!\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tz = pytz.timezone('Asia/Shanghai')\n",
    "def ts_to_date(timestamp):\n",
    "    return datetime.fromtimestamp(timestamp//1000, tz).strftime('%Y-%m-%d')\n",
    "\n",
    "def time_to_ts(ctime):\n",
    "    try:\n",
    "        # 先尝试解析包含小时和分钟的格式\n",
    "        timeArray = time.strptime(ctime, '%Y/%m/%d %H:%M')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # 如果失败，尝试只有日期的格式\n",
    "            timeArray = time.strptime(ctime, '%Y/%m/%d')\n",
    "        except ValueError:\n",
    "            # 如果仍然失败，记录错误或返回一个默认值\n",
    "            print(f\"Failed to parse date: {ctime}\")\n",
    "            return None\n",
    "    return int(time.mktime(timeArray))*1000\n",
    "\n",
    "class TraceUtils:\n",
    "    def __init__(self, data_dir, dataset='gaia'):\n",
    "        self.data_dir = data_dir\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def get_trace_by_day(self, day: int):\n",
    "        day = f'0{day}' if day < 10 else str(day)\n",
    "        temp = []\n",
    "        for service in os.listdir(self.data_dir):\n",
    "            filepath = os.path.join(self.data_dir, \n",
    "                                                 f'{service}/trace_{service}_2021-07-{day}.csv')\n",
    "            if not os.path.exists(filepath):\n",
    "                continue\n",
    "            temp.append(pd.read_csv(filepath, index_col=0))\n",
    "        data = pd.concat(temp, ignore_index=True)\n",
    "        data['timestamp'] = data['timestamp'].apply(time_to_ts)\n",
    "        return data\n",
    "\n",
    "    def get_trace_by_ts(self, ts):\n",
    "        date = ''.join(ts_to_date(ts).split('-')[1: ])\n",
    "        data = pd.read_csv(os.path.join(self.data_dir, f'trace_{date}.csv')) # 21aiops\n",
    "        return data\n",
    "    \n",
    "    # lagency/duration需要减去子调用的最大值\n",
    "    def data_process(self, start_ts, end_ts):\n",
    "        # day = int(ts_to_date(start_ts).split('-')[-1])\n",
    "        # node = 'service_name' if self.dataset == 'gaia' else 'cmdb_id'\n",
    "        if self.dataset == 'gaia':\n",
    "            node = 'service_name'\n",
    "            column = 'lagency'\n",
    "            df = self.get_trace_by_day(day)\n",
    "            if (start_ts is not None) and (end_ts is not None):\n",
    "                sub_df = df[(df['timestamp']>=start_ts)&(df['timestamp']<end_ts)]\n",
    "            else:\n",
    "                sub_df = df\n",
    "            csub_df = sub_df.groupby(['trace_id', 'parent_id'], as_index=False).max()\n",
    "            csub_df = csub_df[[\n",
    "                    'parent_id', node, column\n",
    "                ]].rename(columns={'parent_id': 'span_id', node: f'c{node}', column: f'c{column}'})\n",
    "            data = pd.merge(sub_df, csub_df, on='span_id', how='left').fillna(0)\n",
    "            data['real_duration'] = data[column] - data[f'c{column}']\n",
    "        elif self.dataset == '21aiops':\n",
    "            df = self.get_trace_by_ts(start_ts)\n",
    "            df['timestamp'] = df['timestamp'] if df['timestamp'].values[0] >= 1e12 else df['timestamp']*1000\n",
    "            data = df[(df['timestamp']>=start_ts)&(df['timestamp']<end_ts)]\n",
    "        elif self.dataset == '22aiops':\n",
    "            node = 'cmdb_id'\n",
    "            column = 'duration'\n",
    "            df = pd.read_csv('/Users/fengxiaoyu/Desktop/PDiagnose/初赛评分数据/trace.csv')\n",
    "            if (start_ts is not None) and (end_ts is not None):\n",
    "                sub_df = df[(df['timestamp']>=start_ts)&(df['timestamp']<end_ts)]\n",
    "            else:\n",
    "                sub_df = df\n",
    "            csub_df = sub_df.groupby(['span_id', 'parent_span'], as_index=False).max()\n",
    "            csub_df = csub_df[[\n",
    "                    'parent_span', node, column\n",
    "                ]].rename(columns={'parent_span': 'span_id', node: f'c{node}', column: f'c{column}'})\n",
    "            data = pd.merge(sub_df, csub_df, on='span_id', how='left').fillna(0)\n",
    "            data['real_duration'] = data[column] - data[f'c{column}']\n",
    "        elif self.dataset == 'platform':\n",
    "            node = 'cmdb_id'\n",
    "            column = 'duration'\n",
    "            df = pd.read_csv('/Users/fengxiaoyu/Desktop/PDiagnose/平台数据集/trace/trace.csv')\n",
    "            if (start_ts is not None) and (end_ts is not None):\n",
    "                sub_df = df[(df['timestamp']>=start_ts)&(df['timestamp']<end_ts)]\n",
    "            else:\n",
    "                sub_df = df\n",
    "            print(df.shape)\n",
    "            csub_df = sub_df.groupby(['span_id', 'parent_span'], as_index=False).max()\n",
    "            csub_df = csub_df[[\n",
    "                    'parent_span', node, column\n",
    "                ]].rename(columns={'parent_span': 'span_id', node: f'c{node}', column: f'c{column}'})\n",
    "            data = pd.merge(sub_df, csub_df, on='span_id', how='left').fillna(0)\n",
    "            data['real_duration'] = data[column] - data[f'c{column}']\n",
    "        else:\n",
    "            raise Exception('Unknow dataset!')\n",
    "        return data\n",
    "    \n",
    "class TraceAnalysis():\n",
    "    def __init__(self, cases, data_dir, pid, load, dataset='gaia', config=None):\n",
    "        super().__init__()\n",
    "        self.id = pid\n",
    "        self.cases = cases.iloc[pid*load: (pid+1)*load]\n",
    "        self.tu = TraceUtils(data_dir, dataset)\n",
    "        self.config = config\n",
    "        self.dataset = dataset\n",
    "        if config is None:\n",
    "            self.config = {}\n",
    "            self.config['threshold'] = 50 # 认为异常的duration阈值\n",
    "            self.config['minute'] = 60000\n",
    "        self.res = dict(zip(list(self.cases.index), [set() for _ in range(len(self.cases))])) # 报告可疑微服务\n",
    "        self.time_used = None\n",
    "    \n",
    "    def analysis(self):\n",
    "        start_time = time.time()\n",
    "        if self.dataset == 'gaia':\n",
    "            node = 'service_name'\n",
    "        elif self.dataset == '21aiops':\n",
    "            node = 'cmdb_id'\n",
    "        elif self.dataset == '22aiops':\n",
    "            node = 'cmdb_id'\n",
    "        elif self.dataset == 'platform':\n",
    "            node = 'cmdb_id'\n",
    "        else:\n",
    "            raise Exception('Unknow dataset!')\n",
    "        for case_id, case in self.cases.iterrows():\n",
    "            start_ts = int(case['st_time'])*1000000\n",
    "            end_ts = int(case['ed_time'])*1000000\n",
    "            print(start_ts)\n",
    "            df = self.tu.data_process(start_ts, end_ts) \n",
    "            chosen_df = df[df['real_duration']>self.config['threshold']]\n",
    "            self.res[case_id].update(list(chosen_df[node].unique()))\n",
    "            self.res[case_id].update(list(chosen_df[f'c{node}'].unique()))\n",
    "            if 0 in self.res[case_id]:\n",
    "                self.res[case_id].remove(0)\n",
    "            if np.nan in self.res[case_id]:\n",
    "                self.res[case_id].remove(np.nan)\n",
    "        end_time = time.time()\n",
    "        self.time_used = end_time - start_time\n",
    "    \n",
    "    def save_res(self, savepath):\n",
    "        for key in self.res:\n",
    "            self.res[key] = list(self.res[key])\n",
    "        with open(savepath, 'w') as f:\n",
    "            json.dump(self.res, f)\n",
    "        print(f'{self.id} Time used: ', self.time_used)\n",
    "        print('Save successfully!')\n",
    "    \n",
    "    def run(self):\n",
    "        self.analysis()\n",
    "        self.save_res(f'{self.dataset}/trace/{self.dataset}_trace_{self.id}.json')\n",
    "        with open(f'{self.dataset}/trace/time_used_{self.id}', 'w') as f:\n",
    "            f.write(f'{self.time_used}')\n",
    "\n",
    "# 22挑战赛 配置\n",
    "trace_path = '/Users/fengxiaoyu/Desktop/PDiagnose/平台数据集/trace/trace.csv'\n",
    "label_path = '/Users/fengxiaoyu/Desktop/PDiagnose/run_table.csv'\n",
    "demo_labels = pd.read_csv(label_path, index_col=0)\n",
    "processes = []\n",
    "# 只创建一个实例\n",
    "pid = 0\n",
    "load = len(demo_labels[(demo_labels['data_type'] == 'test')])\n",
    "analyzer = TraceAnalysis(demo_labels[(demo_labels['data_type'] == 'test')], trace_path, pid, load, 'platform')\n",
    "analyzer.analysis()\n",
    "analyzer.save_res(f'{analyzer.dataset}/trace/{analyzer.dataset}_trace_{analyzer.id}.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
